<?xml version="1.0" encoding="UTF-8"?>
<project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns="http://maven.apache.org/POM/4.0.0"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>cn.moretv.doraemon</groupId>
    <artifactId>doraemon</artifactId>
    <packaging>pom</packaging>
    <version>1.0-SNAPSHOT</version>
    <modules>
        <module>data-reader</module>
        <module>algorithm</module>
        <module>reorder</module>
        <module>data-writer</module>
        <module>common</module>
        <module>test</module>
        <module>test-distribution</module>
        <module>kafka-sink</module>

    </modules>

    <!--当前集群组件版本-->
    <properties>
        <doraemon.version>1.1-SNAPSHOT</doraemon.version>

        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <package.output.dir>${project.build.directory}</package.output.dir>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <scala.version>2.11.6</scala.version>
        <scala.binary.version>2.11</scala.binary.version>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
        <slf4j.version>1.7.10</slf4j.version>
        <log4j2.version>2.4.1</log4j2.version>
        <phoenix.version>4.10.0-HBase-1.2</phoenix.version>
        <spark.version>2.1.2</spark.version>
        <hadoop.version>2.6.0</hadoop.version>
        <!--生产环境 hive使用2.1.1,但是spark的内建hive版本为1.2.1-->
        <hive.version>1.2.1</hive.version>
        <kafka.version>1.1.0</kafka.version>
        <ai.h2o.version>2.1.2</ai.h2o.version>
        <couchbase.version>2.5.3</couchbase.version>
    </properties>


    <!--dependencyManagement只会影响现有依赖的配置，但不会引入依赖.
在多模块Maven项目中，dependencyManagement几乎是必不可少的，因为只有它是才能够有效地帮我们维护依赖一致性.-->
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.scala-lang</groupId>
                <artifactId>scala-library</artifactId>
                <version>${scala.version}</version>
            </dependency>
            <dependency>
                <groupId>junit</groupId>
                <artifactId>junit</artifactId>
                <version>4.12</version>
                <scope>test</scope>
            </dependency>

            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-hive_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-core_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-sql_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-graphx_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-mllib_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.hive</groupId>
                <artifactId>hive-jdbc</artifactId>
                <version>${hive.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.hadoop</groupId>
                <artifactId>hadoop-common</artifactId>
                <version>${hadoop.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.hadoop</groupId>
                <artifactId>hadoop-hdfs</artifactId>
                <version>${hadoop.version}</version>
            </dependency>

            <!-- runtime表示只在运行时使用，如JDBC驱动，适用运行和测试阶段。在编码阶段只是用slf4j-api的接口代码，所以将
             日志系统的实现jar都设置为runtime-->
            <dependency>
                <groupId>org.apache.logging.log4j</groupId>
                <artifactId>log4j-slf4j-impl</artifactId>
                <version>${log4j2.version}</version>
                <scope>runtime</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <!--global dependencies,每个子模块都会引用的依赖-->
    <dependencies>
        <!-- 使用slf4j作为简单日志门面，允许最终用户在部署其应用时使用其所希望的日志System -->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>${slf4j.version}</version>
        </dependency>
    </dependencies>

    <distributionManagement>
        <repository>
            <id>nexus-releases</id>
            <name>Nexus Repository</name>
            <url>http://nexus.whaley.cn:8081/nexus/content/repositories/releases/</url>
        </repository>
        <snapshotRepository>
            <id>nexus-snapshots</id>
            <name>Nexus Repository</name>
            <url>http://nexus.whaley.cn:8081/nexus/content/repositories/snapshots</url>
        </snapshotRepository>
    </distributionManagement>

    <build>
        <!--<sourceDirectory>src/main/scala</sourceDirectory>-->
        <!--<testSourceDirectory>src/test/scala</testSourceDirectory>-->
        <!--通过 pluginManagement 来对依赖的插件进行统一的管理-->
        <plugins>

            <plugin>
                <groupId>org.scala-tools</groupId>
                <artifactId>maven-scala-plugin</artifactId>
                <version>2.15.2</version>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <sourceDir>src/main/scala</sourceDir>
                    <scalaVersion>${scala.version}</scalaVersion>
                    <jvmArgs>
                        <jvmArg>-Xms64m</jvmArg>
                        <jvmArg>-Xmx1024m</jvmArg>
                    </jvmArgs>
                </configuration>
            </plugin>

            <plugin>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.1</version>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>

        </plugins>
    </build>


    <profiles>
        <profile>
            <id>deploy</id>
            <dependencies>

                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-core_2.11</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_2.11</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
            </dependencies>

        </profile>
    </profiles>

</project>